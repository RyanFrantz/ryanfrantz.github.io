---
layout: post
title: AI is not Understanding
tags:
  - AI
type: post
status: publish
published: true
---

AI, specifically large language models (LLMs), are not a replacement for
understanding or experience.

Imagine you ask your favorite LLM for a set of recipes that adhere to a certain
theme, say, Thai cuisine. You may receive a collection of instructions,
including the necessary ingredients and steps to prepare them, but this is not
enough to prepare the dishes adequately. So many important answers that affect
the _execution_ of your meal are outstanding:

* Where can you source the ingredients?
* Should ingredients be fresh? Or can any be dried/frozen/processed? 
* How does one manage the preparation and cooking of the recipes to minimize the
  amount of time and resources (energy, tools) required?
* Is it useful to prepare anything in advance?
* Should multiple people participate in preparing the meal? What does
  coordination look like?

However, if you are practiced at cooking, if you understand basic (and perhaps
some advanced) techniques, you are more likely to be successful in making your
Thai plates. You may even be able to identify improvements in a recipe or
patterns across them, to make better use of your time. Your practice supports
your understanding of the art of cooking. That understanding undergirds your
experience.

Without that practice, understanding, and experience, any answer an LLM provides
is superficial. But in _your_ hands, it can be incredibly useful. Because you
can make _sense_ of it.

All this is to say that LLMs are simply a tool. But a powerful tool that can
augment work we do, when leveraged by those with the necessary experience to
reason about the output it generates. Now, by no means, am I implying that LLMs
should not be used by those without experience. In fact, I think LLMs can
augment anyone's work, at different levels. Part of building experience is
learning to ask different/better questions and observing the results. One of the
benefits of LLMs is that they are trained on large corpuses of text [1] so there
is a high probability that some of the answers to your prompts will contain new
information that you can use to explore topics more deeply or in novel ways. But
remember to always seek out _multiple_ primary sources to refine and support
your understanding.

[1] Caveat: I am not addressing the quality of training sets nor the potential
for them to contain biased context or incorrect/misleading information. There
are more qualified folks in the world that can speak on that topic.
